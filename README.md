# ðŸ•·ï¸ E-Commerce Product URL Crawler

This project implements a **scalable**, **robust**, and **asynchronous web crawler** built using **Python**, **Playwright**, and a **Streamlit UI**. The goal is to efficiently discover and extract all valid **product URLs** from leading fashion e-commerce platforms.

---

## ðŸ“¦ Features

- âœ… Intelligent product URL detection using multiple regex patterns
- ðŸš€ Asynchronous crawling with Playwright for high performance
- ðŸ” Auto-scroll and deep-link navigation for lazy-loaded content
- ðŸ§± Robust error handling and domain-specific crawling strategies
- ðŸ–¥ï¸ Interactive **Streamlit Web UI** to crawl by entering supported domain URLs
- ðŸ“¤ Outputs clean, unique, and structured product URLs in both `.txt` and `.json` format

---

## ðŸ›ï¸ Supported Domains

This version supports the following:

- [Virgio](https://www.virgio.com/)
- [TataCliq](https://www.tatacliq.com/)
- [Nykaa Fashion](https://www.nykaafashion.com/)
- [Westside](https://www.westside.com/)

âš ï¸ *Crawler is domain-specific. Only enter one of the above domains in the UI to crawl product URLs.*

---

## ðŸ§  Approach & Logic

### 1ï¸âƒ£ URL Discovery Strategy

Each domain uses unique patterns for product pages. The crawler applies multiple **regular expressions** to detect and validate URLs:

```python
PRODUCT_PATTERNS = [
  re.compile(r"/products/[a-zA-Z0-9\-]+$"),                     # Virgio, Westside
  re.compile(r"/p-mp[0-9]{8,}"),                                # TataCliq
  re.compile(r"/p/[a-zA-Z0-9\-]+$"),                            # Nykaa
  re.compile(r"/collections/.*/products/[a-zA-Z0-9\-]+$"),      # Shopify variants
  re.compile(r"/products/[a-zA-Z0-9\-]+-[0-9]+$"),              # Additional formats
]
```

### 2ï¸âƒ£ Crawling Strategy

- Starts at homepage of the domain
- Scrolls multiple times to trigger lazy-loaded products
- Follows up to 3 internal deep-links based on `href` patterns
- Extracts and filters all valid product URLs

---

## ðŸ–¥ï¸ Streamlit UI

- Users can launch `streamlit_app.py`
- Enter a **supported domain** from the list
- View product URLs directly in the browser

![Screenshot 2025-05-10 123855](https://github.com/user-attachments/assets/68dc392d-5cc6-47e9-87ae-27aa9831c01d)
---

## ðŸ› ï¸ Project Structure

```bash
ðŸ“ ecommerce-crawler
â”œâ”€â”€ crawler_playwright.py        # Core async crawler logic
â”œâ”€â”€ streamlit_app.py             # Frontend UI using Streamlit
â”œâ”€â”€ product_urls_output.txt      # Output in plain text format
â”œâ”€â”€ product_urls_output.json     # Output in JSON format
â””â”€â”€ requirements.txt             # Python dependencies
```

---

## ðŸŒ± Future Scalability

- ðŸ”Œ Add support for more e-commerce platforms via regex & scroll-depth tuning
- ðŸŒ Deploy UI and backend to cloud (Render, EC2, Docker, etc.)
- ðŸ“ˆ Performance tuning using concurrency & page prefetching
- ðŸ“Š Real-time dashboard with crawl stats & URL classification
- ðŸ§ª Automated testing & health-checks for each domain crawl

---

## ðŸ“Ž How to Run

```bash
# Backend Only
python crawler_playwright.py

# Streamlit UI
streamlit run streamlit_app.py
```

---

## ðŸš« Deployment Limitation

> **Note:** Due to the use of **Playwright**, free-tier hosting platforms (like Render, Vercel, etc.) do not support headless browser environments without paid plans.  
> To preserve **performance optimization** and **future scalability**, weâ€™ve chosen not to compromise by switching to a lighter alternative.  
> As a result, the current version is not deployed online and needs to be run locally.
